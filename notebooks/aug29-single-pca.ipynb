{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8deb071201ed71fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Emulate full spectrum using PCA\n",
    "\n",
    "GP emulation of 6S for a complete spectrum using PCA.\n",
    "\n",
    "**Author:** Brian Schubert &lt;<schubert.b@northeastern.edu>&gt;\n",
    "\n",
    "**Date:** 28 August 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import pathlib\n",
    "import math\n",
    "from typing import Final\n",
    "\n",
    "import alive_progress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rtm_wrapper.parameters as rtm_param\n",
    "import scipy.stats.qmc as sci_qmc\n",
    "import sklearn.decomposition as skl_decomp\n",
    "import sklearn.gaussian_process as skl_gp\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.base as skl_base\n",
    "import xarray as xr\n",
    "from rtm_wrapper.engines.sixs import PySixSEngine, pysixs_default_inputs\n",
    "from rtm_wrapper.execution import ConcurrentExecutor\n",
    "from rtm_wrapper.simulation import SweepSimulation\n",
    "\n",
    "\n",
    "from scratch_emulator import sweep_hash, unit2range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025f71fff519476",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Set wavelength and input parameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8aef7a9a61e9c0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fixed spectrum to simulate.\n",
    "WAVELENGTHS: Final = np.arange(0.2, 2.5, 0.025)  # micrometers\n",
    "\n",
    "# Atmosphere parameter ranges to simulate.\n",
    "OZONE_RANGE: Final = (0.25, 0.45)  # cm-atm\n",
    "WATER_RANGE: Final = (1, 4)  # g/cm^2\n",
    "AOT_RANGE: Final = (0.05, 0.5)  # 1\n",
    "ZENITH_RANGE: Final = (10, 60)  # degrees\n",
    "\n",
    "INPUT_RANGES: Final = {\n",
    "    \"atmosphere.ozone\": OZONE_RANGE,\n",
    "    \"atmosphere.water\": WATER_RANGE,\n",
    "    \"aerosol_profile.aot\": AOT_RANGE,\n",
    "    # \"geometry.solar_zenith\": ZENITH_RANGE,\n",
    "}\n",
    "\n",
    "# Model output to emulate.\n",
    "target_output: Final = \"total_transmission\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define base 6S inputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d04f3359f676140"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_inputs = pysixs_default_inputs().replace(\n",
    "    atmosphere=rtm_param.AtmosphereWaterOzone(),\n",
    "    aerosol_profile=rtm_param.AerosolAOTSingleLayer(profile=\"Maritime\", height=100),\n",
    ")\n",
    "\n",
    "\n",
    "def param_rich_name(param_name: str) -> str:\n",
    "    meta = base_inputs.get_metadata(param_name)\n",
    "    return f\"{meta.get('title', param_name)} (${meta.get('unit', '?')}$)\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36f69188c2ff7149"
  },
  {
   "cell_type": "markdown",
   "id": "d283bcdd6ff46f67",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Run true 6S simulation\n",
    "\n",
    "## Sample atmosphere input ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a3899549e4463",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of LHS samples to draw.\n",
    "NUM_SAMPLES: Final = 100\n",
    "\n",
    "# Draw LHS samples.\n",
    "rng = np.random.default_rng(2023_08_28)\n",
    "lhs_sampler = sci_qmc.LatinHypercube(d=len(INPUT_RANGES), seed=rng)\n",
    "raw_samples = lhs_sampler.random(NUM_SAMPLES)\n",
    "\n",
    "# Draw Poisson disk samples\n",
    "# pd_sampler = sci_qmc.PoissonDisk(d=2, seed=rng, radius=0.18)\n",
    "# raw_samples = pd_sampler.random(NUM_SAMPLES)\n",
    "# assert len(raw_samples) == NUM_SAMPLES, \"failed to draw enough samples - try decreasing radius\"\n",
    "\n",
    "# Rescale LHS samples to parameter ranges.\n",
    "input_samples = {\n",
    "    input_name: unit2range(raw_samples[:, sample_column], *input_range)\n",
    "    for sample_column, (input_name, input_range) in enumerate(INPUT_RANGES.items())\n",
    "}\n",
    "\n",
    "# Rescale LHS samples to parameter ranges.\n",
    "# ozone_samples = unit2range(raw_samples[:, 0], *OZONE_RANGE)\n",
    "# water_samples = unit2range(raw_samples[:, 1], *WATER_RANGE)\n",
    "# # aot_samples = unit2range(raw_samples[:, 1], *AOT_RANGE)\n",
    "# target_alt_samples  =unit2range(raw_samples[:, 2], TARGET_ALT_RANGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68176760b202f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot atmosphere input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3f72e6000b72b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"}, figsize=(8,8))\n",
    "# ax.scatter(ozone_samples, water_samples, aot_samples)\n",
    "\n",
    "param_combos = list(itertools.combinations(INPUT_RANGES.keys(), r=2))\n",
    "ncols = math.floor(math.sqrt(len(param_combos)))\n",
    "nrows = math.ceil(len(param_combos) / ncols)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, 8))\n",
    "\n",
    "for ax, (param_x, param_y) in zip(axs.flat, param_combos):\n",
    "    ax.scatter(input_samples[param_x], input_samples[param_y], s=15)\n",
    "    ax.set_xlim(INPUT_RANGES[param_x])\n",
    "    ax.set_ylim(INPUT_RANGES[param_y])\n",
    "    ax.set_xlabel(param_rich_name(param_x))\n",
    "    ax.set_ylabel(param_rich_name(param_y))\n",
    "\n",
    "fig.suptitle(\"Atmosphere Input LHS Samples\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45fbd6d9a214ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Perform simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240c93659511c5c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sweep = SweepSimulation(\n",
    "    {\n",
    "        \"lhs\": input_samples,\n",
    "        \"wavelength.value\": WAVELENGTHS,\n",
    "    },\n",
    "    base=base_inputs,\n",
    ")\n",
    "\n",
    "sweep_path = pathlib.Path(f\"sweep_{sweep_hash(sweep)[:10]}.nc\")\n",
    "\n",
    "if sweep_path.exists():\n",
    "    print(f\"Loading sweep results from '{sweep_path}'\")\n",
    "    train_results = xr.load_dataset(sweep_path)\n",
    "else:\n",
    "\n",
    "    engine = PySixSEngine()\n",
    "    runner = ConcurrentExecutor(max_workers=16)\n",
    "    \n",
    "    with alive_progress.alive_bar(sweep.sweep_size, force_tty=True) as bar:\n",
    "        runner.run(sweep, engine, step_callback=lambda _: bar())\n",
    "\n",
    "    train_results = runner.collect_results()\n",
    "    train_results.to_netcdf(sweep_path)\n",
    "    print(f\"Saved sweep results to '{sweep_path}'\")\n",
    "    \n",
    "train_output = train_results.data_vars[target_output]\n",
    "display(train_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Asses performance vs number of PCs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d354bb6895ebeca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_pipe = sklearn.pipeline.Pipeline(\n",
    "    [\n",
    "        (\"scale\", skl_pre.StandardScaler(with_std=False)),\n",
    "        # white=True - scale down PC components by singular values so that the output features are isotropic.\n",
    "        (\"pca\", skl_decomp.PCA(n_components=None, whiten=True)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "rmse_vs_comps = []\n",
    "\n",
    "test_components = list(range(1, len(WAVELENGTHS) // 4))\n",
    "for num_components in test_components:\n",
    "    pca_pipe.set_params(pca__n_components=num_components)\n",
    "    pca_pipe.fit(train_output)\n",
    "    \n",
    "    proj = pca_pipe.transform(train_output)\n",
    "    round_trip = pca_pipe.inverse_transform(proj)\n",
    "    err = train_output - round_trip\n",
    "    \n",
    "    rmse_vs_comps.append(np.sqrt(np.mean(err ** 2)))\n",
    "    \n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10,6))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(test_components, rmse_vs_comps, \"x-\")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "ax.set_xlabel(\"Number of components\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(test_components, np.cumsum(pca_pipe.named_steps[\"pca\"].explained_variance_ratio_), \"x-\")\n",
    "ax.set_ylabel(\"Cumulative fraction of explained variance\")\n",
    "ax.set_xlabel(\"Number of components\")\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "fig.suptitle(\"PCA Performance vs Number of Components\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80cabe65f9f68b2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix number of PCs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59d5455114747666"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_TRAIN_COMPONENTS: Final = 4\n",
    "pca_pipe.set_params(pca__n_components=NUM_TRAIN_COMPONENTS)\n",
    "pca_pipe.fit(train_output)\n",
    "\n",
    "print(pca_pipe.named_steps[\"pca\"].singular_values_)\n",
    "print(pca_pipe.named_steps[\"pca\"].explained_variance_)\n",
    "\n",
    "for wavelength, pc_contrib in zip(WAVELENGTHS, pca_pipe.named_steps[\"pca\"].components_.T):\n",
    "    print(f\" {wavelength*1e3:6.1f}nm: {' '.join(f'{c:7.4f}' for c in pc_contrib)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd268057bd2cfb60"
  },
  {
   "cell_type": "markdown",
   "id": "bc78d2c30886cadf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd237f673434bc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extract training arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551407caa36f4c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shape: (examples) x (features)\n",
    "x_train = np.stack(\n",
    "    [train_output.coords[parameter].values for parameter in INPUT_RANGES.keys()],\n",
    "    axis=-1,\n",
    ")\n",
    "\n",
    "# Shape: (examples) x (pcs)\n",
    "y_train = pca_pipe.transform(train_output)\n",
    "print(f\"{x_train.shape=}, {y_train.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b5d4dc1dc9d99b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188a1a3cc53dde9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel = 1.0 * skl_gp.kernels.RBF()  # + sklearn_gp.kernels.WhiteKernel()\n",
    "gaussian_process = skl_gp.GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-2,\n",
    "    # alpha=1,\n",
    "    # Normalize targets to zero means, unit variance.\n",
    "    normalize_y=True,\n",
    ")\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(\n",
    "    [\n",
    "        # Rescale input features to [0, 1].\n",
    "        # (\"scale\", sklearn_pre.MinMaxScaler()),\n",
    "        # Rescale to zero mean.\n",
    "        # (\"normalize\", skl_pre.StandardScaler(with_std=False)),\n",
    "        (\"gp\", gaussian_process),\n",
    "    ]\n",
    ")\n",
    "display(pipeline)\n",
    "display(pipeline.named_steps[\"gp\"].kernel.hyperparameters)\n",
    "\n",
    "pc_models = [skl_base.clone(pipeline) for _ in range(NUM_TRAIN_COMPONENTS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944937c3d1ba9995",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b64565d3f9de7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pc_idx, model in enumerate(pc_models):\n",
    "    model.fit(x_train, y_train[:, pc_idx])\n",
    "    print(f\"PC {pc_idx}: {model.named_steps['gp'].kernel_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4758b89c3545d26",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot marginal likelihood surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7de97209cb5273",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pc_idx, model in enumerate(pc_models):\n",
    "    fig = plt.figure(figsize=(10, 5), layout=\"constrained\")\n",
    "    # Extract fit hyperparameter values.\n",
    "    gp = model.named_steps[\"gp\"]\n",
    "    fit_theta = gp.kernel_.theta\n",
    "\n",
    "    # Indices of the two kernel hyperparameters to vary and plot MLL over.\n",
    "    plot_hyper_idx = [0, 1]\n",
    "    plot_hyper_names = [\n",
    "        gaussian_process.kernel.hyperparameters[idx].name for idx in plot_hyper_idx\n",
    "    ]\n",
    "\n",
    "    # Hyperparameter ranges to compute marginal likelihood over.\n",
    "    # Natural log scaled, and centered about fit hyperparameter values found above.\n",
    "    log_sweep_0 = np.log(10) * np.linspace(-5, 5, 60) + fit_theta[plot_hyper_idx[0]]\n",
    "    log_sweep_1 = np.log(10) * np.linspace(-5, 5, 60) + fit_theta[plot_hyper_idx[1]]\n",
    "\n",
    "    mesh_hyper_0, mesh_hyper_1 = np.meshgrid(log_sweep_0, log_sweep_1)\n",
    "    # Preallocate array for likelihood at each hyperparameter combination.\n",
    "    log_marginal_likelihoods = np.zeros(mesh_hyper_0.shape)\n",
    "\n",
    "    # Compute MLL for each hyperparameter combination.\n",
    "    for hyper_0, hyper_1, out in np.nditer(\n",
    "        [mesh_hyper_0, mesh_hyper_1, log_marginal_likelihoods],\n",
    "        op_flags=[[\"readonly\"], [\"readonly\"], [\"writeonly\"]],\n",
    "    ):\n",
    "        theta = fit_theta.copy()\n",
    "        theta[plot_hyper_idx[0]] = hyper_0\n",
    "        theta[plot_hyper_idx[1]] = hyper_1\n",
    "        out[...] = gp.log_marginal_likelihood(theta)\n",
    "\n",
    "    # Plot MLL contours.\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    # Pick contour levels. Increase level density near max to better show peaks.\n",
    "    peak_switch = np.percentile(log_marginal_likelihoods, 85)\n",
    "    levels = np.hstack(\n",
    "        (\n",
    "            np.linspace(log_marginal_likelihoods.min(), peak_switch, 40)[:-1],\n",
    "            np.linspace(peak_switch, log_marginal_likelihoods.max(), 5),\n",
    "        )\n",
    "    )\n",
    "    # levels = 30\n",
    "    art = ax.contour(\n",
    "        np.exp(mesh_hyper_0), np.exp(mesh_hyper_1), log_marginal_likelihoods, levels\n",
    "    )\n",
    "    ax.plot(*np.exp(fit_theta), \"x\")\n",
    "    ax.set_xlabel(plot_hyper_names[0])\n",
    "    ax.set_ylabel(plot_hyper_names[1])\n",
    "\n",
    "    # Plot 3D MLL surface.\n",
    "    ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "    ax.computed_zorder = False  # Prevent surface from hiding point, https://stackoverflow.com/q/51241367/11082165\n",
    "    ax.view_init(elev=30, azim=-135)\n",
    "    zlims = ax.get_zlim()\n",
    "    ax.scatter(\n",
    "        [fit_theta[0] / np.log(10)],\n",
    "        [fit_theta[1] / np.log(10)],\n",
    "        [gp.log_marginal_likelihood(fit_theta)],\n",
    "        c=\"r\",\n",
    "        s=5,\n",
    "        zorder=2,\n",
    "    )\n",
    "    ax.plot_surface(\n",
    "        mesh_hyper_0 / np.log(10),\n",
    "        mesh_hyper_1 / np.log(10),\n",
    "        log_marginal_likelihoods,\n",
    "        # cmap=\"coolwarm\",\n",
    "        zorder=1,\n",
    "    )\n",
    "    ax.contour(\n",
    "        mesh_hyper_0 / np.log(10),\n",
    "        mesh_hyper_1 / np.log(10),\n",
    "        log_marginal_likelihoods,\n",
    "        levels=levels,\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(f\"log10({plot_hyper_names[0]})\")\n",
    "    ax.set_ylabel(f\"log10({plot_hyper_names[1]})\")\n",
    "    # ax.set_zlabel(\"log mll\")\n",
    "    fig.suptitle(f\"PC {pc_idx}: Marginal Likelihood vs Hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66a5042b232afb5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Asses Emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c000cf8d246e3a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee024357f5169f90",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_size = 10\n",
    "\n",
    "dense_input_test = {\n",
    "    param_name: np.linspace(*param_range, grid_size)\n",
    "    for param_name, param_range in INPUT_RANGES.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d93323b010415",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Obtain actual sim results for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_sweep = SweepSimulation(\n",
    "    {\n",
    "        **dense_input_test,\n",
    "        \"wavelength.value\": WAVELENGTHS,\n",
    "    },\n",
    "    base=base_inputs,\n",
    ")\n",
    "\n",
    "test_sweep_path = pathlib.Path(f\"sweep_{sweep_hash(test_sweep)[:10]}.nc\")\n",
    "\n",
    "if test_sweep_path.exists():\n",
    "    print(f\"Loading sweep results from '{sweep_path}'\")\n",
    "    test_results = xr.load_dataset(test_sweep_path)\n",
    "else:\n",
    "\n",
    "    engine = PySixSEngine()\n",
    "    runner = ConcurrentExecutor(max_workers=20)\n",
    "    \n",
    "    with alive_progress.alive_bar(test_sweep.sweep_size, force_tty=True) as bar:\n",
    "        runner.run(test_sweep, engine, step_callback=lambda _: bar())\n",
    "\n",
    "    test_results = runner.collect_results()\n",
    "    test_results.to_netcdf(test_sweep_path)\n",
    "    print(f\"Saved sweep results to '{test_sweep_path}'\")\n",
    "    \n",
    "test_output = test_results.data_vars[target_output]\n",
    "display(test_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37a925eb57ec95fd"
  },
  {
   "cell_type": "markdown",
   "id": "686174b713f59934",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extract test arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422dadaa06317aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_input_meshes = np.meshgrid(\n",
    "    *dense_input_test.values(),\n",
    "    indexing=\"ij\",\n",
    ")\n",
    "assert test_output.dims[-1] == \"wavelength.value\"\n",
    "\n",
    "x_test = np.hstack([mesh.reshape(-1, 1) for mesh in dense_input_meshes])\n",
    "y_test_wl = test_output.values.reshape(-1, len(WAVELENGTHS))\n",
    "y_test_pc = pca_pipe.transform(y_test_wl)\n",
    "\n",
    "print(f\"{x_test.shape=}, {y_test_wl.shape=} {y_test_pc.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211973260b130393",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8d4d490c81a16",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pc_pred_means = []\n",
    "pc_pred_stds = []\n",
    "pc_pred_errors = []\n",
    "pc_y_shaped = []\n",
    "\n",
    "grid_shape = dense_input_meshes[0].shape\n",
    "\n",
    "for pc_index, model in enumerate(pc_models):\n",
    "    mean, std = model.predict(x_test, return_std=True)\n",
    "    pc_pred_means.append(mean.reshape(grid_shape))\n",
    "    pc_pred_stds.append(std.reshape(grid_shape))\n",
    "    pc_pred_errors.append((y_test_pc[:, pc_index] - mean).reshape(grid_shape))\n",
    "    pc_y_shaped.append(y_test_pc[:, pc_index].reshape(grid_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc2b448d2e972c5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b065932796b89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pc_idx in range(NUM_TRAIN_COMPONENTS):\n",
    "    print(f\"PC {pc_idx}:\")\n",
    "    rmse = np.sqrt(np.mean(pc_pred_errors[pc_idx]**2))\n",
    "    \n",
    "    abs_error = np.abs(pc_pred_errors[pc_idx])\n",
    "    \n",
    "    print(f\"  RMSE: {rmse:0.2f}\")\n",
    "    print(f\"  Avg abs err: {np.mean(abs_error):0.2f}\")\n",
    "    print(f\"  Max abs err: {np.max(abs_error):0.2f}\")\n",
    "    print(f\"  Avg rel err: {np.mean(abs_error/pc_y_shaped[pc_idx]):0.2%}\")\n",
    "    print(f\"  Max rel err: {np.max(abs_error/pc_y_shaped[pc_idx]):0.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad86f6051242bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot posterior mean, std, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0b929f7cf4062",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pc_index in range(NUM_TRAIN_COMPONENTS):\n",
    "    param_idx_combos = list(itertools.combinations(range(len(INPUT_RANGES)), r=2))\n",
    "    param_names = list(INPUT_RANGES.keys())\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=len(param_idx_combos),\n",
    "        ncols=4,\n",
    "        figsize=(12, 3 * len(param_idx_combos)),\n",
    "        sharex=\"row\",\n",
    "        sharey=\"row\",\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "    \n",
    "    for ax_row, (param_x_idx, param_y_idx) in zip(axs, param_idx_combos):\n",
    "        local_mesh_x, local_mesh_y = np.meshgrid(\n",
    "            dense_input_test[param_names[param_x_idx]],\n",
    "            dense_input_test[param_names[param_y_idx]],\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "    \n",
    "        other_dims = tuple(\n",
    "            i for i in range(len(INPUT_RANGES)) if i not in (param_x_idx, param_y_idx)\n",
    "        )\n",
    "    \n",
    "        pred_mean_only = pc_pred_means[pc_index].max(axis=other_dims)\n",
    "        y_test_only = pc_y_shaped[pc_index].max(axis=other_dims)\n",
    "        pred_std_only = pc_pred_stds[pc_index].max(axis=other_dims)\n",
    "        pred_error_only = pc_pred_errors[pc_index].max(axis=other_dims)\n",
    "    \n",
    "        vmin = min(pred_mean_only.min(), y_test_only.min())\n",
    "        vmax = max(pred_mean_only.max(), y_test_only.max())\n",
    "    \n",
    "        # Plot predicted mean surface.\n",
    "        ax = ax_row[0]\n",
    "        art = ax.pcolormesh(\n",
    "            local_mesh_x, local_mesh_y, pred_mean_only, vmin=vmin, vmax=vmax\n",
    "        )\n",
    "        ax.plot(\n",
    "            input_samples[param_names[param_x_idx]],\n",
    "            input_samples[param_names[param_y_idx]],\n",
    "            \"o\",\n",
    "            color=\"k\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "    \n",
    "        cbar = fig.colorbar(art)\n",
    "    \n",
    "        # Plot true output surface.\n",
    "        ax = ax_row[1]\n",
    "        art = ax.pcolormesh(local_mesh_x, local_mesh_y, y_test_only, vmin=vmin, vmax=vmax)\n",
    "        ax.plot(\n",
    "            input_samples[param_names[param_x_idx]],\n",
    "            input_samples[param_names[param_y_idx]],\n",
    "            \"o\",\n",
    "            color=\"k\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "    \n",
    "        fig.colorbar(art)\n",
    "    \n",
    "        # Plot predicted variance surface.\n",
    "        ax = ax_row[2]\n",
    "        art = ax.pcolormesh(local_mesh_x, local_mesh_y, pred_std_only)\n",
    "        ax.plot(\n",
    "            input_samples[param_names[param_x_idx]],\n",
    "            input_samples[param_names[param_y_idx]],\n",
    "            \"o\",\n",
    "            color=\"k\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "    \n",
    "        fig.colorbar(art)\n",
    "    \n",
    "        # Plot error surface.\n",
    "        ax = ax_row[3]\n",
    "        art = ax.pcolormesh(\n",
    "            local_mesh_x, local_mesh_y, 100 * np.abs(pred_error_only) / y_test_only\n",
    "        )\n",
    "        ax.plot(\n",
    "            input_samples[param_names[param_x_idx]],\n",
    "            input_samples[param_names[param_y_idx]],\n",
    "            \"o\",\n",
    "            color=\"k\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "    \n",
    "        fig.colorbar(art)\n",
    "    \n",
    "        ax_row[0].set_ylabel(\n",
    "            f\"{param_rich_name(param_names[param_x_idx])}\\nvs\\n{param_rich_name(param_names[param_y_idx])}\"\n",
    "        )\n",
    "    \n",
    "    axs[0, 0].set_title(\"Posterior Mean\")\n",
    "    axs[0, 1].set_title(\"True Output\")\n",
    "    axs[0, 2].set_title(\"Posterior Std\")\n",
    "    axs[0, 3].set_title(\"% Error\")\n",
    "    fig.suptitle(f\"PC {pc_index} Emulator Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "427ac043defef1a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
