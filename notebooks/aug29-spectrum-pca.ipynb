{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Emulate full spectrum using PCA\n",
    "\n",
    "GP emulation of 6S for a complete spectrum using PCA.\n",
    "\n",
    "**Author:** Brian Schubert &lt;<schubert.b@northeastern.edu>&gt;\n",
    "\n",
    "**Date:** 28 August 2023\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8deb071201ed71fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import math\n",
    "import pathlib\n",
    "import random\n",
    "from typing import Final\n",
    "\n",
    "import alive_progress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rtm_wrapper.parameters as rtm_param\n",
    "import scipy.stats.qmc as sci_qmc\n",
    "import sklearn.base as skl_base\n",
    "import sklearn.decomposition as skl_decomp\n",
    "import sklearn.gaussian_process as skl_gp\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import xarray as xr \n",
    "from rtm_wrapper.engines.sixs import PySixSEngine, pysixs_default_inputs\n",
    "from rtm_wrapper.execution import ConcurrentExecutor\n",
    "from rtm_wrapper.simulation import SweepSimulation\n",
    "\n",
    "from scratch_emulator import sweep_hash, unit2range, brute_maximin\n",
    "\n",
    "MAX_SWEEP_WORKERS: Final = 24"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34f40030138541b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set wavelength and input parameter ranges"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90c04c4a3604a8ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fixed spectrum to simulate.\n",
    "# Note: even though 6S's lower bound is 0.2 um, it generates a handful of nan values\n",
    "# below 0.25 um.\n",
    "WAVELENGTHS: Final = np.arange(0.25, 4, 0.0025)  # micrometers\n",
    "\n",
    "# Atmosphere parameter ranges to simulate.\n",
    "OZONE_RANGE: Final = (0.25, 0.45)  # cm-atm\n",
    "WATER_RANGE: Final = (1, 4)  # g/cm^2\n",
    "AOT_RANGE: Final = (0.05, 0.5)  # 1\n",
    "ZENITH_COSINE_RANGE: Final = (0.5, 1)  # 1\n",
    "\n",
    "INPUT_RANGES: Final = {\n",
    "    \"atmosphere.ozone\": OZONE_RANGE,\n",
    "    \"atmosphere.water\": WATER_RANGE,\n",
    "    \"aerosol_profile.aot\": AOT_RANGE,\n",
    "    \"geometry.solar_zenith.cosine\": ZENITH_COSINE_RANGE,\n",
    "}\n",
    "\n",
    "# Model output to emulate.\n",
    "target_output: Final = \"total_transmission\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "487bcc86aa0399be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define base 6S inputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3904039d60758a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_inputs = pysixs_default_inputs().replace(\n",
    "    atmosphere=rtm_param.AtmosphereWaterOzone(),\n",
    "    aerosol_profile=rtm_param.AerosolAOTSingleLayer(profile=\"Maritime\", height=100),\n",
    "    geometry__solar_zenith=rtm_param.AngleCosineParameter(),\n",
    ")\n",
    "\n",
    "\n",
    "def param_rich_name(param_name: str) -> str:\n",
    "    meta = base_inputs.get_metadata(param_name)\n",
    "    return f\"{meta.get('title', param_name)} (${meta.get('unit', '?')}$)\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b022ff47db2a57ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run true 6S simulation\n",
    "\n",
    "## Sample atmosphere input ranges"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7640311f35e7e81b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of LHS samples to draw.\n",
    "NUM_SAMPLES: Final = 100\n",
    "\n",
    "# Draw LHS samples.\n",
    "rng = np.random.default_rng(2023_09_01)\n",
    "lhs_sampler = sci_qmc.LatinHypercube(d=len(INPUT_RANGES), seed=rng)\n",
    "raw_samples = lhs_sampler.random(NUM_SAMPLES)\n",
    "\n",
    "# raw_samples = brute_maximin(\n",
    "#         NUM_SAMPLES, len(INPUT_RANGES), iterations=10_000, pick=\"min\", metric=\"euclidean\", rng=rng\n",
    "# )  # metric=lambda u,v: np.min(np.abs(u-v))\n",
    "\n",
    "# Rescale LHS samples to parameter ranges.\n",
    "input_samples = {\n",
    "    input_name: unit2range(raw_samples[:, sample_column], *input_range)\n",
    "    for sample_column, (input_name, input_range) in enumerate(INPUT_RANGES.items())\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc3ec991911ea07e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot atmosphere input samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5abc019f352c78a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_combos = list(itertools.combinations(INPUT_RANGES.keys(), r=2))\n",
    "ncols = math.floor(math.sqrt(len(param_combos)))\n",
    "nrows = math.ceil(len(param_combos) / ncols)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, 8))\n",
    "\n",
    "for ax, (param_x, param_y) in zip(axs.flat, param_combos):\n",
    "    ax.scatter(input_samples[param_x], input_samples[param_y], s=15)\n",
    "    ax.set_xlim(INPUT_RANGES[param_x])\n",
    "    ax.set_ylim(INPUT_RANGES[param_y])\n",
    "    ax.set_xlabel(param_rich_name(param_x))\n",
    "    ax.set_ylabel(param_rich_name(param_y))\n",
    "\n",
    "fig.suptitle(\"Atmosphere Input LHS Samples\")\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463e37b83a7ac636"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d48c0c6e64ec5450"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_sweep = SweepSimulation(\n",
    "    {\n",
    "        \"lhs\": input_samples,\n",
    "        \"wavelength.value\": WAVELENGTHS,\n",
    "    },\n",
    "    base=base_inputs,\n",
    ")\n",
    "\n",
    "train_sweep_path = pathlib.Path(f\"sweep_{sweep_hash(train_sweep)[:10]}.nc\")\n",
    "\n",
    "if train_sweep_path.exists():\n",
    "    print(f\"Loading sweep results from '{train_sweep_path}'\")\n",
    "    train_results = xr.load_dataset(train_sweep_path)\n",
    "else:\n",
    "    engine = PySixSEngine()\n",
    "    runner = ConcurrentExecutor(max_workers=MAX_SWEEP_WORKERS)\n",
    "\n",
    "    with alive_progress.alive_bar(train_sweep.sweep_size, force_tty=True) as bar:\n",
    "        runner.run(train_sweep, engine, step_callback=lambda _: bar())\n",
    "\n",
    "    train_results = runner.collect_results()\n",
    "    train_results.to_netcdf(train_sweep_path)\n",
    "    print(f\"Saved sweep results to '{train_sweep_path}'\")\n",
    "\n",
    "train_output = train_results.data_vars[target_output]\n",
    "display(train_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "419ddb3d8ba533e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Asses performance vs number of PCs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "caba7e06e628d0f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_pipe = sklearn.pipeline.Pipeline(\n",
    "    [\n",
    "        (\"scale\", skl_pre.StandardScaler(with_std=False)),\n",
    "        # white=True - scale down PC components by singular values so that the output features are isotropic.\n",
    "        (\"pca\", skl_decomp.PCA(n_components=None, whiten=True)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "rmse_vs_comps = []\n",
    "\n",
    "test_components = list(range(1, min(len(WAVELENGTHS) // 4, NUM_SAMPLES, 20)))\n",
    "for num_components in test_components:\n",
    "    pca_pipe.set_params(pca__n_components=num_components)\n",
    "    pca_pipe.fit(train_output)\n",
    "\n",
    "    proj = pca_pipe.transform(train_output)\n",
    "    round_trip = pca_pipe.inverse_transform(proj)\n",
    "    err = train_output - round_trip\n",
    "\n",
    "    rmse_vs_comps.append(np.sqrt(np.mean(err**2)))\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 6))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.semilogy(test_components, rmse_vs_comps, \"x-\")\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "ax.set_xlabel(\"Number of components\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(\n",
    "    test_components,\n",
    "    np.cumsum(pca_pipe.named_steps[\"pca\"].explained_variance_ratio_),\n",
    "    \"x-\",\n",
    ")\n",
    "ax.set_ylabel(\"Cumulative fraction of explained variance\")\n",
    "ax.set_xlabel(\"Number of components\")\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "fig.suptitle(\"PCA Performance vs Number of Components\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f10806a4b8afe005"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix number of PCs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4b2dd1cd0557fea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_TRAIN_COMPONENTS: Final = 8\n",
    "pca_pipe.set_params(pca__n_components=NUM_TRAIN_COMPONENTS)\n",
    "pca_pipe.fit(train_output)\n",
    "\n",
    "print(pca_pipe.named_steps[\"pca\"].singular_values_)\n",
    "print(pca_pipe.named_steps[\"pca\"].explained_variance_)\n",
    "\n",
    "for wavelength, pc_contrib in zip(\n",
    "    WAVELENGTHS, pca_pipe.named_steps[\"pca\"].components_.T\n",
    "):\n",
    "    print(f\" {wavelength*1e3:6.1f}nm: {' '.join(f'{c:7.4f}' for c in pc_contrib)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84cdff1af66c5aac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Emulator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb2ff7c01f27c726"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract training arrays"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "676429c85ebb54c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shape: (examples) x (features)\n",
    "x_train = np.stack(\n",
    "    [train_output.coords[parameter].values for parameter in INPUT_RANGES.keys()],\n",
    "    axis=-1,\n",
    ")\n",
    "\n",
    "# Shape: (examples) x (pcs)\n",
    "y_train = pca_pipe.transform(train_output)\n",
    "print(f\"{x_train.shape=}, {y_train.shape=}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "236423eebbf2b390"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create GP model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16943bd674f332b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kernel = 1.0 * skl_gp.kernels.RBF()  # + sklearn_gp.kernels.WhiteKernel()\n",
    "gaussian_process = skl_gp.GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-1,\n",
    "    # alpha=1,\n",
    "    # Normalize targets to zero means, unit variance.\n",
    "    normalize_y=True,\n",
    ")\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(\n",
    "    [\n",
    "        # Rescale input features to [0, 1].\n",
    "        # (\"scale\", sklearn_pre.MinMaxScaler()),\n",
    "        # Rescale to zero mean.\n",
    "        # (\"normalize\", skl_pre.StandardScaler(with_std=False)),\n",
    "        (\"gp\", gaussian_process),\n",
    "    ]\n",
    ")\n",
    "display(pipeline)\n",
    "display(pipeline.named_steps[\"gp\"].kernel.hyperparameters)\n",
    "\n",
    "pc_models = [skl_base.clone(pipeline) for _ in range(NUM_TRAIN_COMPONENTS)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "435c4ac034225fe1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fd01e7594b3ae53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pc_idx, model in enumerate(pc_models):\n",
    "    model.fit(x_train, y_train[:, pc_idx])\n",
    "    print(f\"PC {pc_idx}: {model.named_steps['gp'].kernel_}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49817f426d71fe72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot marginal likelihood surface"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2da6ff538d4b054c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pc_idx, model in enumerate(pc_models):\n",
    "    fig = plt.figure(figsize=(10, 5), layout=\"constrained\")\n",
    "    # Extract fit hyperparameter values.\n",
    "    gp = model.named_steps[\"gp\"]\n",
    "    fit_theta = gp.kernel_.theta\n",
    "\n",
    "    # Indices of the two kernel hyperparameters to vary and plot MLL over.\n",
    "    plot_hyper_idx = [0, 1]\n",
    "    plot_hyper_names = [\n",
    "        gaussian_process.kernel.hyperparameters[idx].name for idx in plot_hyper_idx\n",
    "    ]\n",
    "\n",
    "    # Hyperparameter ranges to compute marginal likelihood over.\n",
    "    # Natural log scaled, and centered about fit hyperparameter values found above.\n",
    "    log_sweep_0 = np.log(10) * np.linspace(-5, 5, 60) + fit_theta[plot_hyper_idx[0]]\n",
    "    log_sweep_1 = np.log(10) * np.linspace(-5, 5, 60) + fit_theta[plot_hyper_idx[1]]\n",
    "\n",
    "    mesh_hyper_0, mesh_hyper_1 = np.meshgrid(log_sweep_0, log_sweep_1)\n",
    "    # Preallocate array for likelihood at each hyperparameter combination.\n",
    "    log_marginal_likelihoods = np.zeros(mesh_hyper_0.shape)\n",
    "\n",
    "    # Compute MLL for each hyperparameter combination.\n",
    "    for hyper_0, hyper_1, out in np.nditer(\n",
    "        [mesh_hyper_0, mesh_hyper_1, log_marginal_likelihoods],\n",
    "        op_flags=[[\"readonly\"], [\"readonly\"], [\"writeonly\"]],\n",
    "    ):\n",
    "        theta = fit_theta.copy()\n",
    "        theta[plot_hyper_idx[0]] = hyper_0\n",
    "        theta[plot_hyper_idx[1]] = hyper_1\n",
    "        out[...] = gp.log_marginal_likelihood(theta)\n",
    "\n",
    "    # Plot MLL contours.\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    # Pick contour levels. Increase level density near max to better show peaks.\n",
    "    peak_switch = np.percentile(log_marginal_likelihoods, 85)\n",
    "    levels = np.hstack(\n",
    "        (\n",
    "            np.linspace(log_marginal_likelihoods.min(), peak_switch, 40)[:-1],\n",
    "            np.linspace(peak_switch, log_marginal_likelihoods.max(), 5),\n",
    "        )\n",
    "    )\n",
    "    # levels = 30\n",
    "    art = ax.contour(\n",
    "        np.exp(mesh_hyper_0), np.exp(mesh_hyper_1), log_marginal_likelihoods, levels\n",
    "    )\n",
    "    ax.plot(*np.exp(fit_theta), \"x\")\n",
    "    ax.set_xlabel(\"magnitude scale\")\n",
    "    ax.set_ylabel(\"length scale\")\n",
    "\n",
    "    # Plot 3D MLL surface.\n",
    "    ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "    ax.computed_zorder = False  # Prevent surface from hiding point, https://stackoverflow.com/q/51241367/11082165\n",
    "    ax.view_init(elev=30, azim=-135)\n",
    "    zlims = ax.get_zlim()\n",
    "    ax.scatter(\n",
    "        [fit_theta[0] / np.log(10)],\n",
    "        [fit_theta[1] / np.log(10)],\n",
    "        [gp.log_marginal_likelihood(fit_theta)],\n",
    "        c=\"r\",\n",
    "        s=5,\n",
    "        zorder=2,\n",
    "    )\n",
    "    ax.plot_surface(\n",
    "        mesh_hyper_0 / np.log(10),\n",
    "        mesh_hyper_1 / np.log(10),\n",
    "        log_marginal_likelihoods,\n",
    "        # cmap=\"coolwarm\",\n",
    "        zorder=1,\n",
    "    )\n",
    "    ax.contour(\n",
    "        mesh_hyper_0 / np.log(10),\n",
    "        mesh_hyper_1 / np.log(10),\n",
    "        log_marginal_likelihoods,\n",
    "        levels=levels,\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(f\"log10(magnitude scale)\")\n",
    "    ax.set_ylabel(f\"log10(length scale)\")\n",
    "    # ax.set_zlabel(\"log mll\")\n",
    "    fig.suptitle(f\"PC {pc_idx}: Marginal Likelihood vs Hyperparameters\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b113d1a5faa011ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Asses Emulator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1f6edd04aa2622f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80cd85d07dff5f50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_size = 8\n",
    "\n",
    "dense_input_test = {\n",
    "    param_name: np.linspace(*param_range, grid_size)\n",
    "    for param_name, param_range in INPUT_RANGES.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6685219b49d92d57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtain actual sim results for test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e6776c9e0f64f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_sweep = SweepSimulation(\n",
    "    {\n",
    "        **dense_input_test,\n",
    "        \"wavelength.value\": WAVELENGTHS,\n",
    "    },\n",
    "    base=base_inputs,\n",
    ")\n",
    "\n",
    "test_sweep_path = pathlib.Path(f\"sweep_{sweep_hash(test_sweep)[:10]}.nc\")\n",
    "\n",
    "if test_sweep_path.exists():\n",
    "    print(f\"Loading sweep results from '{test_sweep_path}'\")\n",
    "    test_results = xr.load_dataset(test_sweep_path)\n",
    "else:\n",
    "    engine = PySixSEngine()\n",
    "    runner = ConcurrentExecutor(max_workers=MAX_SWEEP_WORKERS)\n",
    "\n",
    "    with alive_progress.alive_bar(test_sweep.sweep_size, force_tty=True) as bar:\n",
    "        runner.run(test_sweep, engine, step_callback=lambda _: bar())\n",
    "\n",
    "    test_results = runner.collect_results()\n",
    "    test_results.to_netcdf(test_sweep_path)\n",
    "    print(f\"Saved sweep results to '{test_sweep_path}'\")\n",
    "\n",
    "test_output = test_results.data_vars[target_output]\n",
    "display(test_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adda361e0e327538"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract test arrays"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92737a7b7a8301c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dense_input_meshes = np.meshgrid(\n",
    "    *dense_input_test.values(),\n",
    "    indexing=\"ij\",\n",
    ")\n",
    "assert test_output.dims[-1] == \"wavelength.value\"\n",
    "\n",
    "x_test = np.hstack([mesh.reshape(-1, 1) for mesh in dense_input_meshes])\n",
    "y_test_wl = test_output.values.reshape(-1, len(WAVELENGTHS))\n",
    "y_test_pc = pca_pipe.transform(y_test_wl)\n",
    "\n",
    "print(f\"{x_test.shape=}, {y_test_wl.shape=} {y_test_pc.shape=}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a76f38b45f768337"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate model on test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60ced09066055499"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pc_pred_means = []\n",
    "pc_pred_stds = []\n",
    "pc_pred_errors = []\n",
    "pc_y_shaped = []\n",
    "\n",
    "grid_shape = dense_input_meshes[0].shape\n",
    "\n",
    "for pc_index, model in enumerate(pc_models):\n",
    "    mean, std = model.predict(x_test, return_std=True)\n",
    "    pc_pred_means.append(mean.reshape(grid_shape))\n",
    "    pc_pred_stds.append(std.reshape(grid_shape))\n",
    "    pc_pred_errors.append((y_test_pc[:, pc_index] - mean).reshape(grid_shape))\n",
    "    pc_y_shaped.append(y_test_pc[:, pc_index].reshape(grid_shape))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4f378af97a2e05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute metrics on PC output feature"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60b9c41a8060fa33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pc_idx in range(NUM_TRAIN_COMPONENTS):\n",
    "    print(f\"PC {pc_idx}:\")\n",
    "    rmse = np.sqrt(np.mean(pc_pred_errors[pc_idx] ** 2))\n",
    "\n",
    "    abs_error = np.abs(pc_pred_errors[pc_idx])\n",
    "\n",
    "    print(f\"  RMSE: {rmse:0.2f}\")\n",
    "    print(f\"  Avg abs err: {np.mean(abs_error):0.2f}\")\n",
    "    print(f\"  Max abs err: {np.max(abs_error):0.2f}\")\n",
    "    print(f\"  Avg rel err: {np.mean(abs_error/np.abs(pc_y_shaped[pc_idx])):0.2%}\")\n",
    "    print(f\"  Max rel err: {np.max(abs_error/np.abs(pc_y_shaped[pc_idx])):0.2%}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e2243c4d3456d8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot posterior mean, std, error for PC output feature"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96170631d33feb3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for pc_index in range(NUM_TRAIN_COMPONENTS):\n",
    "    param_idx_combos = list(itertools.combinations(range(len(INPUT_RANGES)), r=2))\n",
    "    param_names = list(INPUT_RANGES.keys())\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=len(param_idx_combos),\n",
    "        ncols=5,\n",
    "        figsize=(16, 3 * len(param_idx_combos)),\n",
    "        # sharex=\"row\",\n",
    "        # sharey=\"row\",\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    for ax_row, (param_x_idx, param_y_idx) in zip(axs, param_idx_combos):\n",
    "        local_mesh_x, local_mesh_y = np.meshgrid(\n",
    "            dense_input_test[param_names[param_x_idx]],\n",
    "            dense_input_test[param_names[param_y_idx]],\n",
    "            indexing=\"ij\",\n",
    "        )\n",
    "\n",
    "        other_dims = tuple(\n",
    "            i for i in range(len(INPUT_RANGES)) if i not in (param_x_idx, param_y_idx)\n",
    "        )\n",
    "\n",
    "        pred_mean_only = pc_pred_means[pc_index].mean(axis=other_dims)\n",
    "        y_test_only = pc_y_shaped[pc_index].mean(axis=other_dims)\n",
    "        pred_std_only = pc_pred_stds[pc_index].mean(axis=other_dims)\n",
    "        pred_error_only = pc_pred_errors[pc_index].mean(axis=other_dims)\n",
    "\n",
    "        vmin = min(pred_mean_only.min(), y_test_only.min())\n",
    "        vmax = max(pred_mean_only.max(), y_test_only.max())\n",
    "\n",
    "        # Plot predicted mean surface.\n",
    "        ax = ax_row[0]\n",
    "        art = ax.pcolormesh(\n",
    "            local_mesh_x, local_mesh_y, pred_mean_only, vmin=vmin, vmax=vmax\n",
    "        )\n",
    "        ax.plot(\n",
    "            input_samples[param_names[param_x_idx]],\n",
    "            input_samples[param_names[param_y_idx]],\n",
    "            \"o\",\n",
    "            color=\"k\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "\n",
    "        cbar = fig.colorbar(art)\n",
    "\n",
    "        # Plot true output surface.\n",
    "        ax = ax_row[1]\n",
    "        art = ax.pcolormesh(\n",
    "            local_mesh_x, local_mesh_y, y_test_only, vmin=vmin, vmax=vmax\n",
    "        )\n",
    "        ax.plot(\n",
    "            input_samples[param_names[param_x_idx]],\n",
    "            input_samples[param_names[param_y_idx]],\n",
    "            \"o\",\n",
    "            color=\"k\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "\n",
    "        fig.colorbar(art)\n",
    "\n",
    "        # Plot predicted variance surface.\n",
    "        ax = ax_row[2]\n",
    "        art = ax.pcolormesh(local_mesh_x, local_mesh_y, pred_std_only)\n",
    "        ax.plot(\n",
    "            input_samples[param_names[param_x_idx]],\n",
    "            input_samples[param_names[param_y_idx]],\n",
    "            \"o\",\n",
    "            color=\"k\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "\n",
    "        fig.colorbar(art)\n",
    "\n",
    "        # Plot error surface.\n",
    "        ax = ax_row[3]\n",
    "        art = ax.pcolormesh(local_mesh_x, local_mesh_y, pred_error_only)\n",
    "        ax.plot(\n",
    "            input_samples[param_names[param_x_idx]],\n",
    "            input_samples[param_names[param_y_idx]],\n",
    "            \"o\",\n",
    "            color=\"k\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "\n",
    "        fig.colorbar(art)\n",
    "\n",
    "        ax_row[0].set_ylabel(\n",
    "            f\"{param_rich_name(param_names[param_x_idx])}\\nvs\\n{param_rich_name(param_names[param_y_idx])}\"\n",
    "        )\n",
    "        \n",
    "        # Plot histogram of residues\n",
    "        ax = ax_row[4]\n",
    "        residue_norm = pred_error_only / pred_std_only\n",
    "        counts, bins = np.histogram(residue_norm.flat, bins=20)\n",
    "        ax.stairs(counts, bins)\n",
    "        ax.set_xlim(-4, 4)\n",
    "        \n",
    "        \n",
    "\n",
    "    axs[0, 0].set_title(\"Posterior Mean\")\n",
    "    axs[0, 1].set_title(\"True Output\")\n",
    "    axs[0, 2].set_title(\"Posterior Std\")\n",
    "    axs[0, 3].set_title(\"Error\")\n",
    "    axs[0, 4].set_title(\"Residue/Std Hist\")\n",
    "    fig.suptitle(f\"PC {pc_index} Emulator Performance\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd1fbd7d3efb9e30"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6e8e2c434fd9c8c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.stats as sci_stats\n",
    "fig, axs = plt.subplots(\n",
    "        nrows=NUM_TRAIN_COMPONENTS,\n",
    "        ncols=3,\n",
    "        figsize=(8.5, 3 * NUM_TRAIN_COMPONENTS),\n",
    "        # sharex=\"row\",\n",
    "        # sharey=\"row\",\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "r = sci_stats.norm()\n",
    "\n",
    "num_bins = 40\n",
    "    \n",
    "for ax_row, pc_index in zip(axs, range(NUM_TRAIN_COMPONENTS)):\n",
    "    residue_norm =  pc_pred_errors[pc_index] / pc_pred_stds[pc_index]\n",
    "    \n",
    "    ax = ax_row[0]\n",
    "    hist_count, hist_bins = np.histogram(residue_norm, bins=num_bins, density=True)\n",
    "    ax.stairs(hist_count, hist_bins)\n",
    "    hist_range = np.linspace(hist_bins[0], hist_bins[-1], 1000)\n",
    "    ax.plot(hist_range, r.pdf(hist_range), '--', color=\"tab:orange\")\n",
    "    \n",
    "    ax = ax_row[1]\n",
    "    pit_counts, pit_bins = np.histogram(r.cdf(residue_norm), bins=num_bins, density=True)\n",
    "    ax.stairs(pit_counts, pit_bins, label=\"Actual\")\n",
    "    ax.axhline([1], linestyle='--', color=\"tab:orange\", label=\"Expected\")\n",
    "    ax.legend(loc=\"upper center\")\n",
    "    \n",
    "    ax = ax_row[2]\n",
    "    osm, osr = sci_stats.probplot(residue_norm.flat, dist=r, fit=False)\n",
    "    ax.plot(osm, osr)\n",
    "    ax.plot(np.linspace(-5, 5, 100), np.linspace(-5, 5, 100), '--', color=\"tab:orange\")\n",
    "    \n",
    "    ax_row[0].set_title(\"Residue Histogram\")\n",
    "    ax_row[1].set_title(f\"PC {pc_index}\\nPIT\")\n",
    "    ax_row[2].set_title(f\"Q-Q\")\n",
    "    ax_row[0].set_xlabel(\"residue / std\")\n",
    "    ax_row[1].set_xlabel(\"x\")\n",
    "    ax_row[2].set_xlabel(\"Theoretical Quantiles\")\n",
    "    ax_row[0].set_ylabel(\"Relative Frequency\")\n",
    "    ax_row[1].set_ylabel(\"Relative Frequency\")\n",
    "    ax_row[2].set_ylabel(\"Ordered Responses\")\n",
    "    ax_row[0].set_xlim(-5, 5)\n",
    "    ax_row[1].set_xlim(0, 1)\n",
    "    ax_row[2].set_xlim(-5, 5)\n",
    "    ax_row[0].set_ylim(0, 0.6)\n",
    "    ax_row[1].set_ylim(0, pit_counts.max()*1.2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "976c5edc552ed4aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute model output spectrum"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af67aded7c7e3e05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # r = sci_stats.norm()\n",
    "# chisq = sci_stats.chisquare(counts, r.pdf(bins[:-1]), axis=None)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90a5aad0419f34fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "pred_mean_wl = pca_pipe.inverse_transform(\n",
    "    np.hstack([m.reshape(-1, 1) for m in pc_pred_means])\n",
    ")\n",
    "\n",
    "std_inverse = copy.deepcopy(pca_pipe.named_steps[\"pca\"])\n",
    "std_inverse.components_ = np.abs(std_inverse.components_)\n",
    "\n",
    "pred_std_wl = np.sqrt(\n",
    "    std_inverse.inverse_transform(\n",
    "        np.hstack([m.reshape(-1, 1)**2 for m in pc_pred_stds])\n",
    "    )\n",
    ")\n",
    "pred_error_wl = y_test_wl - pred_mean_wl\n",
    "\n",
    "pred_mean_wl_shaped = pred_mean_wl.reshape(*grid_shape, len(WAVELENGTHS))\n",
    "pred_std_wl_shaped = pred_std_wl.reshape(*grid_shape, len(WAVELENGTHS))\n",
    "y_test_wl_shaped = y_test_wl.reshape(*grid_shape, len(WAVELENGTHS))\n",
    "pred_error_wl_shaped = pred_error_wl.reshape(*grid_shape, len(WAVELENGTHS))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "427ac043defef1a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate metrics on output spectrum"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e9fa21710ab7bd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Avg abs err {np.mean(np.abs(pred_error_wl)):0.5f}\")\n",
    "print(f\"Max abs err {np.max(np.abs(pred_error_wl)):0.5f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9d9fed22dbc30a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pick wavelength to plot mean, error surfaces for.\n",
    "wavelength_idx = 130\n",
    "\n",
    "param_idx_combos = list(itertools.combinations(range(len(INPUT_RANGES)), r=2))\n",
    "param_names = list(INPUT_RANGES.keys())\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=len(param_idx_combos),\n",
    "    ncols=4,\n",
    "    figsize=(12, 3 * len(param_idx_combos)),\n",
    "    sharex=\"row\",\n",
    "    sharey=\"row\",\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "for ax_row, (param_x_idx, param_y_idx) in zip(axs, param_idx_combos):\n",
    "    local_mesh_x, local_mesh_y = np.meshgrid(\n",
    "        dense_input_test[param_names[param_x_idx]],\n",
    "        dense_input_test[param_names[param_y_idx]],\n",
    "        indexing=\"ij\",\n",
    "    )\n",
    "\n",
    "    other_dims = tuple(\n",
    "        i for i in range(len(INPUT_RANGES)) if i not in (param_x_idx, param_y_idx)\n",
    "    )\n",
    "\n",
    "    pred_mean_only = pred_mean_wl_shaped[..., wavelength_idx].mean(axis=other_dims)\n",
    "    pred_std_only = pred_std_wl_shaped[..., wavelength_idx].mean(axis=other_dims)\n",
    "    y_test_only = y_test_wl_shaped[..., wavelength_idx].mean(axis=other_dims)\n",
    "    pred_error_only = pred_error_wl_shaped[..., wavelength_idx].mean(axis=other_dims)\n",
    "\n",
    "    vmin = min(pred_mean_only.min(), y_test_only.min())\n",
    "    vmax = max(pred_mean_only.max(), y_test_only.max())\n",
    "\n",
    "    # Plot predicted mean surface.\n",
    "    ax = ax_row[0]\n",
    "    art = ax.pcolormesh(\n",
    "        local_mesh_x, local_mesh_y, pred_mean_only, vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    ax.plot(\n",
    "        input_samples[param_names[param_x_idx]],\n",
    "        input_samples[param_names[param_y_idx]],\n",
    "        \"o\",\n",
    "        color=\"k\",\n",
    "        markerfacecolor=\"none\",\n",
    "    )\n",
    "\n",
    "    cbar = fig.colorbar(art)\n",
    "\n",
    "    # Plot true output surface.\n",
    "    ax = ax_row[1]\n",
    "    art = ax.pcolormesh(local_mesh_x, local_mesh_y, y_test_only, vmin=vmin, vmax=vmax)\n",
    "    ax.plot(\n",
    "        input_samples[param_names[param_x_idx]],\n",
    "        input_samples[param_names[param_y_idx]],\n",
    "        \"o\",\n",
    "        color=\"k\",\n",
    "        markerfacecolor=\"none\",\n",
    "    )\n",
    "\n",
    "    fig.colorbar(art)\n",
    "    \n",
    "    # Plot predicted variance surface.\n",
    "    ax = ax_row[2]\n",
    "    art = ax.pcolormesh(local_mesh_x, local_mesh_y, pred_std_only)\n",
    "    ax.plot(\n",
    "        input_samples[param_names[param_x_idx]],\n",
    "        input_samples[param_names[param_y_idx]],\n",
    "        \"o\",\n",
    "        color=\"k\",\n",
    "        markerfacecolor=\"none\",\n",
    "    )\n",
    "\n",
    "    fig.colorbar(art)\n",
    "\n",
    "    # Plot error surface.\n",
    "    ax = ax_row[3]\n",
    "    art = ax.pcolormesh(\n",
    "        local_mesh_x, local_mesh_y, pred_error_only\n",
    "    )\n",
    "    ax.plot(\n",
    "        input_samples[param_names[param_x_idx]],\n",
    "        input_samples[param_names[param_y_idx]],\n",
    "        \"o\",\n",
    "        color=\"k\",\n",
    "        markerfacecolor=\"none\",\n",
    "    )\n",
    "\n",
    "    fig.colorbar(art)\n",
    "\n",
    "    ax_row[0].set_ylabel(\n",
    "        f\"{param_rich_name(param_names[param_x_idx])}\\nvs\\n{param_rich_name(param_names[param_y_idx])}\"\n",
    "    )\n",
    "\n",
    "axs[0, 0].set_title(\"Posterior Mean\")\n",
    "axs[0, 1].set_title(\"True Output\")\n",
    "axs[0, 2].set_title(\"Std\")\n",
    "axs[0, 3].set_title(\"Error\")\n",
    "fig.suptitle(f\"{WAVELENGTHS[wavelength_idx]*1e3:0.1f}nm Emulator Performance\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "967d6b3d9f600445"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rand_input = tuple(\n",
    "    random.randint(1, len(input_choices) - 1)\n",
    "    for input_choices in dense_input_test.values()\n",
    ")\n",
    "\n",
    "# rand_input = (rand_input[0], 0, rand_input[2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.plot(\n",
    "    WAVELENGTHS, y_test_wl_shaped[rand_input], label=\"6S\", linewidth=1.5, linestyle=\"--\"\n",
    ")\n",
    "ax.plot(\n",
    "    WAVELENGTHS,\n",
    "    pred_mean_wl_shaped[rand_input], \n",
    "    label=\"Emulator\",\n",
    "    linewidth=1.5,\n",
    "    linestyle=\"-.\",\n",
    ")\n",
    "pca_temp = pca_pipe.inverse_transform(pca_pipe.transform(y_test_wl_shaped[rand_input].reshape(1, -1))).reshape(-1, 1)\n",
    "ax.plot(\n",
    "    WAVELENGTHS,\n",
    "    pca_temp.flat,\n",
    "    label=\"PCA\",\n",
    "    linewidth=1.5,\n",
    "    linestyle=\":\",\n",
    ")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(WAVELENGTHS[0], WAVELENGTHS[-1])\n",
    "ax.set_xlabel(param_rich_name(\"wavelength.value\"))\n",
    "ax.set_ylabel(test_output.attrs.get(\"title\", \"Output\"))\n",
    "ax.set_title(\n",
    "    f\"{', '.join(f'{param}={value_choice[value_index]:0.2f}' for param, value_choice, value_index in zip(test_output.dims, dense_input_test.values(), rand_input)) }\",\n",
    "    fontsize=10,\n",
    ")\n",
    "ax.fill_between(WAVELENGTHS, np.zeros_like(WAVELENGTHS), pred_std_wl_shaped[rand_input], alpha=0.3, color=\"tab:blue\")\n",
    "ax.fill_between(\n",
    "    WAVELENGTHS, \n",
    "    pred_mean_wl_shaped[rand_input] - pred_std_wl_shaped[rand_input], \n",
    "    pred_mean_wl_shaped[rand_input] + pred_std_wl_shaped[rand_input], \n",
    "    alpha=0.2, \n",
    "    color=\"tab:blue\",\n",
    "    label=\"$\\pm 1$ std.\",\n",
    ")\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "ignore_idx = (y_test_wl_shaped < 0.2).any(axis=0).any(axis=0).any(axis=0).any(axis=0)\n",
    "temp = pred_error_wl_shaped.copy()\n",
    "# temp[rand_input + (ignore_idx,)] = float(\"nan\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(\n",
    "    WAVELENGTHS,\n",
    "    temp[rand_input],\n",
    "    color=\"black\",\n",
    "    linestyle=\":\",\n",
    "    label=\"Emulator Error\",\n",
    ")\n",
    "ax2.plot(\n",
    "    WAVELENGTHS,\n",
    "    (-pca_temp.reshape(1, -1)+ y_test_wl_shaped[rand_input]).flat,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"PCA Error\",\n",
    ")\n",
    "ax2.set_ylabel(\"Error\")\n",
    "max_error = np.max(np.abs(pred_error_wl_shaped))\n",
    "ax2.set_ylim(-2 * max_error, 2 * max_error)\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "fig.suptitle(\"True 6S Output vs Emulator Output\");"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2af8a0ace06be1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51c3924a9d6762fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(16,16), sharex=\"col\", layout=\"constrained\")\n",
    "\n",
    "plot_components = 15 # NUM_TRAIN_COMPONENTS -5\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_prop_cycle(\n",
    "        color=plt.cm.viridis(np.linspace(0, 1, plot_components))\n",
    "    )\n",
    "    ax.set_xlim(WAVELENGTHS[0], WAVELENGTHS[-1]*1.1)\n",
    "\n",
    "    ax.set_xlabel(param_rich_name(\"wavelength.value\"))\n",
    "    ax.set_ylabel(f'Error in {test_output.attrs.get(\"title\", \"Output\")}')\n",
    "    ax.axhline(0, color=\"k\")\n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "for n_components in range(1, plot_components + 1):\n",
    "    remove_components = NUM_TRAIN_COMPONENTS - n_components\n",
    "    x = np.hstack([m.reshape(-1, 1) for m in pc_pred_means])\n",
    "    x[:, -remove_components:] = 0\n",
    "    \n",
    "    pred_mean_wl_part = pca_pipe.inverse_transform(x)\n",
    "    pred_error_wl_part = y_test_wl - pred_mean_wl_part\n",
    "    \n",
    "    axs[0].plot(WAVELENGTHS, np.abs(pred_error_wl_part).mean(axis=0), label=f\"#PC={n_components}\", linewidth=0.5)\n",
    "    axs[1].plot(WAVELENGTHS, np.abs(pred_error_wl_part).max(axis=0), label=f\"#PC={n_components}\", linewidth=0.5)\n",
    "\n",
    "\n",
    "axs[0].legend(ncols=2)\n",
    "axs[0].set_title(\"Mean Abs. Error\")\n",
    "axs[1].set_title(\"Max Abs. Error\")\n",
    "fig.suptitle(\"Posterior Error for Varying #PCs\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ac4bf702c6f226b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wavelength-space Residues\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79c2aedd4afbca97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.stats as sci_stats\n",
    "\n",
    "# wavelength_idx = random.randint(0, len(WAVELENGTHS)) # 370 345 934 577\n",
    "\n",
    "display_wavelengths = sorted(np.random.choice(len(WAVELENGTHS), 10))\n",
    "\n",
    "for wavelength_idx in display_wavelengths:\n",
    "    fig, axs = plt.subplots(\n",
    "            nrows=1,\n",
    "            ncols=3,\n",
    "            figsize=(12, 4),\n",
    "            # sharex=\"row\",\n",
    "            # sharey=\"row\",\n",
    "            layout=\"constrained\",\n",
    "        )\n",
    "    \n",
    "    pc_inverse_map = np.sqrt(pca_pipe.named_steps[\"pca\"].explained_variance_[:, np.newaxis]) * pca_pipe.named_steps[\"pca\"].components_\n",
    "    \n",
    "    wavelength_pc_weights = pc_inverse_map[:, wavelength_idx]\n",
    "    \n",
    "    expected_var = (wavelength_pc_weights**2).sum()/wavelength_pc_weights.sum()\n",
    "    # scale=std\n",
    "    r = sci_stats.norm(scale=expected_var**0.5) \n",
    "    \n",
    "    num_bins = 40\n",
    "        \n",
    "    residue_norm =  pred_error_wl_shaped / pred_std_wl_shaped\n",
    "    \n",
    "    residue_norm_single = residue_norm[..., wavelength_idx]\n",
    "    residue_norm_single = residue_norm_single[~np.isnan(residue_norm_single)]\n",
    "    print(residue_norm_single.shape)\n",
    "    \n",
    "    ax = axs[0]\n",
    "    hist_count, hist_bins = np.histogram(residue_norm_single, bins=num_bins, density=True)\n",
    "    ax.stairs(hist_count, hist_bins)\n",
    "    hist_range = np.linspace(hist_bins[0], hist_bins[-1], 1000)\n",
    "    ax.plot(hist_range, r.pdf(hist_range), '--', color=\"tab:orange\")\n",
    "    \n",
    "    ax = axs[1]\n",
    "    pit_counts, pit_bins = np.histogram(r.cdf(residue_norm_single), bins=num_bins, density=True)\n",
    "    ax.stairs(pit_counts, pit_bins, label=\"Actual\")\n",
    "    ax.axhline([1], linestyle='--', color=\"tab:orange\", label=\"Expected\")\n",
    "    ax.legend(loc=\"upper center\")\n",
    "    \n",
    "    ax = axs[2]\n",
    "    osm, osr = sci_stats.probplot(residue_norm_single.flat, dist=r, fit=False)\n",
    "    ax.plot(osm, osr)\n",
    "    ax.plot(np.linspace(-5, 5, 100), np.linspace(-5, 5, 100), '--', color=\"tab:orange\")\n",
    "    \n",
    "    axs[0].set_title(\"Residue Histogram\")\n",
    "    axs[2].set_title(f\"Q-Q\")\n",
    "    axs[1].set_title(f\"{WAVELENGTHS[wavelength_idx]*1e3:.1f}nm ({wavelength_idx})\\nPIT\")\n",
    "    axs[0].set_xlabel(\"residue / std\")\n",
    "    axs[1].set_xlabel(\"x\")\n",
    "    axs[2].set_xlabel(\"Theoretical Quantiles\")\n",
    "    axs[0].set_ylabel(\"Relative Frequency\")\n",
    "    axs[1].set_ylabel(\"Relative Frequency\")\n",
    "    axs[2].set_ylabel(\"Ordered Responses\")\n",
    "    axs[0].set_xlim(-2, 2)\n",
    "    axs[1].set_xlim(0, 1)\n",
    "    axs[2].set_xlim(-2, 2)\n",
    "    axs[0].set_ylim(0, 3.5)\n",
    "    axs[1].set_ylim(0, pit_counts.max()*1.2);"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16ad40d6435adcad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(pca_pipe.named_steps[\"pca\"].components_**2).sum(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "172d8fed4d2bbb73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_pipe.named_steps[\"pca\"].components_[:, wavelength_idx]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9edf9d18077a1df7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.sqrt(pca_pipe.named_steps[\"pca\"].explained_variance_[:, np.newaxis]) * pca_pipe.named_steps[\"pca\"].components_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf09994cd4fdc004"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wavelength_idx"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0c76898b8f5c209"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_std_wl_shaped[..., wavelength_idx]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ade85b93a4db04f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
